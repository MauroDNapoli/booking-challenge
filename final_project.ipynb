{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regional-connecticut",
   "metadata": {},
   "source": [
    "### Booking Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "copyrighted-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.notebook import tqdm\n",
    "from torchsummary import summary\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "endangered-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label_df(df: pd.DataFrame):\n",
    "    '''\n",
    "    adds label to the dataset \n",
    "    removes the last row for every trip\n",
    "    removes sequences shorter than 3\n",
    "    order the df starting from longer sequences\n",
    "    '''\n",
    "    df_chunks = []\n",
    "    df['label'] = df['city_id'].shift(-1)\n",
    "    idx_labels = np.unique(df.index)\n",
    "    \n",
    "    for idx in tqdm(idx_labels):\n",
    "        temp_dataset = df.loc[idx].head(-1)\n",
    "        if type(temp_dataset)==pd.DataFrame and len(temp_dataset)>=3:\n",
    "            df_chunks.append(temp_dataset)\n",
    "    \n",
    "    df_chunks = sorted(df_chunks, key=lambda x: len(x), reverse=True)\n",
    "    new_df = pd.concat(df_chunks)\n",
    "\n",
    "    \n",
    "    return new_df\n",
    "\n",
    "\n",
    "def front_padding_sequence(tensors: List, num_features: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Applies front padding to a list of tensors\n",
    "    \"\"\"\n",
    "    sizes = [len(tensor) for tensor in tensors]\n",
    "    max_size = max(sizes)\n",
    "    pad_tensors = []\n",
    "    for q in tensors:\n",
    "        new_tensor = torch.zeros(max_size, num_features)\n",
    "        new_tensor[max_size-len(q):] = q\n",
    "        pad_tensors.append(new_tensor)\n",
    "    \n",
    "    return torch.stack(pad_tensors,dim=0).long()\n",
    "\n",
    "\n",
    "def custom_padding(batch):\n",
    "    '''\n",
    "    pad each batch according to the sequence \n",
    "    with the highest length\n",
    "    '''\n",
    "    features = [sample[0] for sample in batch]\n",
    "    features = front_padding_sequence(features, 2)\n",
    "    labels = [sample[1].unsqueeze(dim=1) for sample in batch]\n",
    "    labels = front_padding_sequence(labels, 1)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "stretch-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_set.csv').set_index('utrip_id')\n",
    "df_train.index = df_train.index.astype(int)\n",
    "df_test = pd.read_csv('test_set.csv').set_index('utrip_id')\n",
    "df_test.index = df_test.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "filled-medication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692075dec7d549b18d38fb62878fd514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/217684 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = preprocess_label_df(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "based-picnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bec7e7008546eda96146b63e8dd084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = preprocess_label_df(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-grenada",
   "metadata": {},
   "source": [
    "### Change utrip_id label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "polish-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['label'].astype(int)\n",
    "df_test['label'] = df_test['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "applied-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "utrip_distinct_train = df_train.index.unique()\n",
    "utrip_train_map = {utrip:i for i, utrip in enumerate(utrip_distinct_train)}\n",
    "df_train = df_train.rename(index=utrip_train_map)\n",
    "\n",
    "utrip_distinct_test = df_test.index.unique()\n",
    "utrip_test_map = {utrip:i for i, utrip in enumerate(utrip_distinct_test)}\n",
    "df_test = df_test.rename(index=utrip_test_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "small-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utrip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>47319</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>36063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>36063</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>36063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>36063</td>\n",
       "      <td>mobile</td>\n",
       "      <td>384</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>36063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>36063</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>3109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>3109</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>3109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     checkin    checkout  city_id device_class  affiliate_id  \\\n",
       "utrip_id                                                                        \n",
       "0         3635431  2016-04-01  2016-04-02    47319       mobile          9924   \n",
       "0         3635431  2016-04-02  2016-04-03    36063       mobile          9924   \n",
       "0         3635431  2016-04-03  2016-04-04    36063       mobile           384   \n",
       "0         3635431  2016-04-04  2016-04-05    36063       mobile          9924   \n",
       "0         3635431  2016-04-05  2016-04-06     3109       mobile          9924   \n",
       "\n",
       "         booker_country hotel_country  label  \n",
       "utrip_id                                      \n",
       "0                Gondal        Gondal  36063  \n",
       "0                Gondal        Gondal  36063  \n",
       "0                Gondal        Gondal  36063  \n",
       "0                Gondal        Gondal   3109  \n",
       "0                Gondal        Gondal   3109  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-bristol",
   "metadata": {},
   "source": [
    "#### Create map for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "green-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_affiliate_id = np.unique(df_train.affiliate_id)\n",
    "affiliate_id_map = {aff_id:i+1 for i, aff_id in enumerate(distinct_affiliate_id)}\n",
    "\n",
    "distinct_checkin_id = np.unique(df_train.checkin)\n",
    "checkin_map = {checkin:i+1 for i, checkin in enumerate(distinct_checkin_id)}\n",
    "\n",
    "distinct_device_class = np.unique(df_train.device_class)\n",
    "device_map = {device:i+1 for i, device in enumerate(distinct_device_class)}\n",
    "\n",
    "distinct_city_id = np.unique([df_train.city_id,df_train.label])\n",
    "city_id_map = {city_id:i+1 for i, city_id in enumerate(distinct_city_id)}\n",
    "\n",
    "distinct_booker_country = np.unique(df_train.booker_country)\n",
    "booker_country_map = {booker_country:i+1 for i, booker_country in enumerate(distinct_booker_country)}\n",
    "\n",
    "distinct_hotel_country = np.unique(df_train.hotel_country)\n",
    "hotel_country_map = {hotel_country:i+1 for i, hotel_country in enumerate(distinct_hotel_country)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "substantial-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['checkin'] = df_train['checkin'].map(lambda x: checkin_map.get(x))\n",
    "df_train['affiliate_id'] = df_train['affiliate_id'].map(lambda x: affiliate_id_map.get(x))\n",
    "df_train['city_id'] = df_train['city_id'].map(lambda x: city_id_map.get(x))\n",
    "df_train['label'] = df_train['label'].map(lambda x: city_id_map.get(x))\n",
    "df_train['booker_country'] = df_train['booker_country'].map(lambda x: booker_country_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "constant-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['checkin'] = df_test['checkin'].map(lambda x: checkin_map.get(x, 0))\n",
    "df_test['affiliate_id'] = df_test['affiliate_id'].map(lambda x: affiliate_id_map.get(x, 0))\n",
    "df_test['city_id'] = df_test['city_id'].map(lambda x: city_id_map.get(x, 0))\n",
    "df_test['label'] = df_test['label'].map(lambda x: city_id_map.get(x, 0))\n",
    "df_test['booker_country'] = df_test['booker_country'].map(lambda x: booker_country_map.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-volume",
   "metadata": {},
   "source": [
    "#### Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "rubber-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookingDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(self.df.index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        city_id = row['city_id'].values\n",
    "        label_id = row['label'].values\n",
    "        affiliate_id = row['affiliate_id']\n",
    "        \n",
    "        city_id = torch.tensor(row['city_id'].values).view(-1, 1)\n",
    "        affiliate_id = torch.tensor(row['affiliate_id'].values).view(-1, 1)\n",
    "        features = torch.cat((city_id, affiliate_id), 1)\n",
    "        features = features.view(-1, 2)\n",
    "        \n",
    "        label_id = torch.tensor(row['label'].values).float()\n",
    "        \n",
    "        return features, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "resistant-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BookingDataset(df_train)\n",
    "train_dl = DataLoader(train_ds, batch_size = 4, shuffle = False, collate_fn=custom_padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-adapter",
   "metadata": {},
   "source": [
    "#### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "adverse-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla RNN using nn.RNN\n",
    "class Vanilla_RNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, output_size):\n",
    "        super(Vanilla_RNN, self).__init__()\n",
    "        \n",
    "        self.city_emb = nn.Embedding(len(city_id_map)+1, emb_size, padding_idx=0)\n",
    "        self.affiliate_emb = nn.Embedding(len(affiliate_id_map)+1, emb_size, padding_idx=0)\n",
    "        \n",
    "        self.rnn = nn.RNN(emb_size*2, hidden_size)\n",
    "        \n",
    "        # here is our g function from the lecture slides\n",
    "        # linear layer turning the i-th hidden state into the i-th output\n",
    "        self.g = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        city_emb = self.city_emb(x[:,:,0])\n",
    "        affiliate_emb = self.affiliate_emb(x[:,:,1])\n",
    "        x = torch.cat((city_emb, affiliate_emb), dim=2)\n",
    "        out, hidden = self.rnn(x)\n",
    "        out = self.g(out)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "stupid-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rnn = Vanilla_RNN(24, 100, 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
