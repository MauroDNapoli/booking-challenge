{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regional-connecticut",
   "metadata": {},
   "source": [
    "### Booking Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "copyrighted-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "from typing import List\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm.notebook import tqdm\n",
    "from torchsummary import summary\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "endangered-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label_df(\n",
    "        df: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    '''\n",
    "    adds label to the dataset \n",
    "    removes the last row for every trip\n",
    "    removes sequences shorter than 3\n",
    "    order the df starting from longer sequences\n",
    "    '''\n",
    "    df_chunks = []\n",
    "    df['label'] = df['city_id'].shift(-1)\n",
    "    idx_labels = np.unique(df.index)\n",
    "\n",
    "    for idx in tqdm(idx_labels):\n",
    "        temp_dataset = df.loc[idx].head(-1)\n",
    "        if type(temp_dataset) == pd.DataFrame and len(temp_dataset) >= 3:\n",
    "            df_chunks.append(temp_dataset)\n",
    "\n",
    "    df_chunks = sorted(df_chunks, key=lambda x: len(x), reverse=True)\n",
    "    new_df = pd.concat(df_chunks)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def front_padding_sequence(tensors: List, num_features: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Applies front padding to a list of tensors\n",
    "    \"\"\"\n",
    "    sizes = [len(tensor) for tensor in tensors]\n",
    "    max_size = max(sizes)\n",
    "    pad_tensors = []\n",
    "    for q in tensors:\n",
    "        new_tensor = torch.zeros(max_size, num_features)\n",
    "        new_tensor[max_size - len(q):] = q\n",
    "        pad_tensors.append(new_tensor)\n",
    "\n",
    "    return torch.stack(pad_tensors, dim=0).long()\n",
    "\n",
    "\n",
    "def custom_padding(batch):\n",
    "    '''\n",
    "    pad each batch according to the sequence \n",
    "    with the highest length\n",
    "    '''\n",
    "    features = [sample[0] for sample in batch]\n",
    "    features = front_padding_sequence(features, 2)\n",
    "    labels = [sample[1].unsqueeze(dim=1) for sample in batch]\n",
    "    labels = front_padding_sequence(labels, 1)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stretch-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../train_set.csv').set_index('utrip_id')\n",
    "df_train.index = df_train.index.astype(int)\n",
    "df_test = pd.read_csv('../test_set.csv').set_index('utrip_id')\n",
    "df_test.index = df_test.index.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "filled-medication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f542b56448401c91e5d72aec22ef53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/217684 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train = preprocess_label_df(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "based-picnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb50a7db1a2a4388af8900bccad72fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70661 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test = preprocess_label_df(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-grenada",
   "metadata": {},
   "source": [
    "### Change utrip_id label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polish-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['label'].astype(int)\n",
    "df_test['label'] = df_test['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "applied-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "utrip_distinct_train = df_train.index.unique()\n",
    "utrip_train_map = {utrip:i for i, utrip in enumerate(utrip_distinct_train)}\n",
    "df_train = df_train.rename(index=utrip_train_map)\n",
    "\n",
    "utrip_distinct_test = df_test.index.unique()\n",
    "utrip_test_map = {utrip:i for i, utrip in enumerate(utrip_distinct_test)}\n",
    "df_test = df_test.rename(index=utrip_test_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "small-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>checkin</th>\n",
       "      <th>checkout</th>\n",
       "      <th>city_id</th>\n",
       "      <th>device_class</th>\n",
       "      <th>affiliate_id</th>\n",
       "      <th>booker_country</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>utrip_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>47319</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>36063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-02</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>36063</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>36063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-03</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>36063</td>\n",
       "      <td>mobile</td>\n",
       "      <td>384</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>36063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-04</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>36063</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>3109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3635431</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>2016-04-06</td>\n",
       "      <td>3109</td>\n",
       "      <td>mobile</td>\n",
       "      <td>9924</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>Gondal</td>\n",
       "      <td>3109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id     checkin    checkout  city_id device_class  affiliate_id  \\\n",
       "utrip_id                                                                        \n",
       "0         3635431  2016-04-01  2016-04-02    47319       mobile          9924   \n",
       "0         3635431  2016-04-02  2016-04-03    36063       mobile          9924   \n",
       "0         3635431  2016-04-03  2016-04-04    36063       mobile           384   \n",
       "0         3635431  2016-04-04  2016-04-05    36063       mobile          9924   \n",
       "0         3635431  2016-04-05  2016-04-06     3109       mobile          9924   \n",
       "\n",
       "         booker_country hotel_country  label  \n",
       "utrip_id                                      \n",
       "0                Gondal        Gondal  36063  \n",
       "0                Gondal        Gondal  36063  \n",
       "0                Gondal        Gondal  36063  \n",
       "0                Gondal        Gondal   3109  \n",
       "0                Gondal        Gondal   3109  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-bristol",
   "metadata": {},
   "source": [
    "#### Create map for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "green-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_affiliate_id = np.unique(df_train.affiliate_id)\n",
    "affiliate_id_map = {aff_id:i+1 for i, aff_id in enumerate(distinct_affiliate_id)}\n",
    "\n",
    "distinct_checkin_id = np.unique(df_train.checkin)\n",
    "checkin_map = {checkin:i+1 for i, checkin in enumerate(distinct_checkin_id)}\n",
    "\n",
    "distinct_device_class = np.unique(df_train.device_class)\n",
    "device_map = {device:i+1 for i, device in enumerate(distinct_device_class)}\n",
    "\n",
    "distinct_city_id = np.unique([df_train.city_id,df_train.label])\n",
    "city_id_map = {city_id:i+1 for i, city_id in enumerate(distinct_city_id)}\n",
    "\n",
    "distinct_booker_country = np.unique(df_train.booker_country)\n",
    "booker_country_map = {booker_country:i+1 for i, booker_country in enumerate(distinct_booker_country)}\n",
    "\n",
    "distinct_hotel_country = np.unique(df_train.hotel_country)\n",
    "hotel_country_map = {hotel_country:i+1 for i, hotel_country in enumerate(distinct_hotel_country)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "substantial-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['checkin'] = df_train['checkin'].map(lambda x: checkin_map.get(x))\n",
    "df_train['affiliate_id'] = df_train['affiliate_id'].map(lambda x: affiliate_id_map.get(x))\n",
    "df_train['city_id'] = df_train['city_id'].map(lambda x: city_id_map.get(x))\n",
    "df_train['label'] = df_train['label'].map(lambda x: city_id_map.get(x))\n",
    "df_train['booker_country'] = df_train['booker_country'].map(lambda x: booker_country_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "constant-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['checkin'] = df_test['checkin'].map(lambda x: checkin_map.get(x, 0))\n",
    "df_test['affiliate_id'] = df_test['affiliate_id'].map(lambda x: affiliate_id_map.get(x, 0))\n",
    "df_test['city_id'] = df_test['city_id'].map(lambda x: city_id_map.get(x, 0))\n",
    "df_test['label'] = df_test['label'].map(lambda x: city_id_map.get(x, 0))\n",
    "df_test['booker_country'] = df_test['booker_country'].map(lambda x: booker_country_map.get(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-volume",
   "metadata": {},
   "source": [
    "#### Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rubber-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookingDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(self.df.index)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        city_id = row['city_id'].values\n",
    "        label_id = row['label'].values\n",
    "        affiliate_id = row['affiliate_id']\n",
    "        \n",
    "        city_id = torch.tensor(row['city_id'].values).view(-1, 1)\n",
    "        affiliate_id = torch.tensor(row['affiliate_id'].values).view(-1, 1)\n",
    "        features = torch.cat((city_id, affiliate_id), 1)\n",
    "        features = features.view(-1, 2)\n",
    "        \n",
    "        label_id = torch.tensor(row['label'].values).float()\n",
    "        \n",
    "        return features, label_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "resistant-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BookingDataset(df_train)\n",
    "train_dl = DataLoader(train_ds, batch_size = 4, shuffle = False, collate_fn=custom_padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-adapter",
   "metadata": {},
   "source": [
    "#### Vanilla RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adverse-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla RNN using nn.RNN\n",
    "class Vanilla_RNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, output_size):\n",
    "        super(Vanilla_RNN, self).__init__()\n",
    "        \n",
    "        self.city_emb = nn.Embedding(len(city_id_map)+1, emb_size, padding_idx=0)\n",
    "        self.affiliate_emb = nn.Embedding(len(affiliate_id_map)+1, emb_size, padding_idx=0)\n",
    "        \n",
    "        self.rnn = nn.RNN(emb_size*2, hidden_size)\n",
    "        \n",
    "        # here is our g function from the lecture slides\n",
    "        # linear layer turning the i-th hidden state into the i-th output\n",
    "        self.g = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        city_emb = self.city_emb(x[:,:,0])\n",
    "        affiliate_emb = self.affiliate_emb(x[:,:,1])\n",
    "        x = torch.cat((city_emb, affiliate_emb), dim=2)\n",
    "        out, hidden = self.rnn(x)\n",
    "        out = self.g(out)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "stupid-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_rnn = Vanilla_RNN(24, 100, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc3b34e",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca008797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.city_emb = nn.Embedding(len(city_id_map)+1, emb_size, padding_idx=0)\n",
    "        self.affiliate_emb = nn.Embedding(len(affiliate_id_map)+1, emb_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(emb_size*2, hidden_size, batch_first=True)\n",
    "        self.g = nn.Linear(hidden_size, len(city_id_map))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        city_emb = self.city_emb(x[:,:,0])\n",
    "        affiliate_emb = self.affiliate_emb(x[:,:,1])\n",
    "        x = torch.cat((city_emb, affiliate_emb), dim=2)\n",
    "        out, hidden = self.lstm(x)\n",
    "        out = self.g(out) \n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "563e92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "92ded55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fun = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(lstm.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "64d78dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_pass(model, dataloader, optimizer, lossFun, backwards=True, print_loss=False):\n",
    "\n",
    "    if backwards == True:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for x, y in tqdm(dataloader):\n",
    "        \n",
    "        output, hidden = model(x)\n",
    "        loss = lossFun(output, y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if backwards == True:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    if print_loss == True:\n",
    "        print(avg_loss)\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9e6efc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551ef548aab94892904c18367fbe6dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected target size (4, 39878), got torch.Size([4, 47, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/46/7r6546gd7lx0tlk7zwckwnlw0000gn/T/ipykernel_58290/3900879928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/46/7r6546gd7lx0tlk7zwckwnlw0000gn/T/ipykernel_58290/2495239510.py\u001b[0m in \u001b[0;36mone_pass\u001b[0;34m(model, dataloader, optimizer, lossFun, backwards, print_loss)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossFun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1048\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2395\u001b[0m         \u001b[0mout_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2397\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected target size {}, got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2398\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected target size (4, 39878), got torch.Size([4, 47, 1])"
     ]
    }
   ],
   "source": [
    "one_pass(lstm, train_dl, optimizer, loss_fun)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
